version: '3.8'

services:
  thewallflower:
    image: ghcr.io/jellman86/thewallflower:latest
    build:
      context: .
      dockerfile: Dockerfile
    container_name: thewallflower
    ports:
      - "${PORT:-8080}:8000"
    volumes:
      - thewallflower-data:/data
    environment:
      - DATABASE_URL=sqlite:///data/thewallflower.db
      - WHISPER_HOST=whisper-live
      - WHISPER_PORT=9090
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - WORKERS=${WORKERS:-1}
      - WAIT_FOR_WHISPER=true
    depends_on:
      whisper-live:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    restart: unless-stopped
    networks:
      - default

  whisper-live:
    # Image selection - set WHISPER_IMAGE in .env:
    #   CPU only:    ghcr.io/collabora/whisperlive-cpu:latest
    #   NVIDIA GPU:  ghcr.io/collabora/whisperlive-gpu:latest
    #   Intel GPU:   ghcr.io/collabora/whisperlive-openvino:latest
    image: ${WHISPER_IMAGE:-ghcr.io/collabora/whisperlive-cpu:latest}
    container_name: whisper-live
    ports:
      - "${WHISPER_PORT:-9090}:9090"
    environment:
      - WHISPER_MODEL=${WHISPER_MODEL:-base.en}
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "9090"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    restart: unless-stopped
    networks:
      - default
    # Intel GPU support - uncomment for Intel iGPU/Arc acceleration
    devices:
       - /dev/dri:/dev/dri
    group_add:
       - video
       - render
    #
    # NVIDIA GPU support - uncomment for NVIDIA CUDA acceleration
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: 1
    #           capabilities: [gpu]

volumes:
  thewallflower-data:
    driver: local

networks:
  default:
    name: ${NETWORK_NAME:-thewallflower-network}
    external: ${NETWORK_EXTERNAL:-false}
